{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8136c936-680e-4460-9a5a-1dca4a9a2d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import multiprocessing\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import warnings\n",
    "\n",
    "from monai.networks import nets\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import enum\n",
    "from IPython import display\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "import natsort\n",
    "\n",
    "from scipy import io\n",
    "import glob\n",
    "\n",
    "import nibabel as nib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d138833-ef6d-4641-af2e-63feaf36841c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "def make_colorbar_with_padding(ax):\n",
    "    \"\"\"\n",
    "    Create colorbar axis that fits the size of a plot - detailed here: http://chris35wills.github.io/matplotlib_axis/\n",
    "    \"\"\"\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "    return(cax) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa6adba-1b47-4a0f-a9e1-0b61716d83b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590e2140-2b2f-4a5e-a7d4-59608397cdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #data load\n",
    "# data_root = '...' \n",
    "# subjects_list=[]\n",
    "# subjects_list = os.listdir(data_root)\n",
    "# subjects_list = natsort.natsorted(subjects_list)\n",
    "\n",
    "# state_dir = '.../CheckPoint/Quantitative_Maps_Generator'\n",
    "# save_inference_dir = '.../inference'\n",
    "\n",
    "#data load\n",
    "data_root = '/hdd/share/test_github_upload/data'\n",
    "subjects_list=[]\n",
    "subjects_list = os.listdir(data_root)\n",
    "subjects_list = natsort.natsorted(subjects_list)\n",
    "\n",
    "state_dir = '/hdd/share/2023_New_Harmonization/src/PhyCHarm_share/CheckPoint/Quantitative_Maps_Generator'\n",
    "save_inference_dir = '/hdd/share/test_github_upload/inference_QM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009ee8eb-2aa7-40f3-bd2f-bcb97de595f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_root, sub_num, num_z_slice, train):\n",
    "        self.data_root = data_root\n",
    "        self.sub_num = sub_num\n",
    "\n",
    "        self.dataset = []\n",
    "        for z in range(num_z_slice):\n",
    "            self.dataset.append(z)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        z = self.dataset[idx]\n",
    "        \n",
    "        T1w_path = glob.glob(f'{self.data_root}/{self.sub_num}/T1w/*.nii.gz')[0]\n",
    "        mask_path =glob.glob(f'{self.data_root}/{self.sub_num}/mask/*.nii.gz')[0]\n",
    "        \n",
    "        T1w = nib.load(T1w_path).get_fdata()[None, ..., z].astype(np.float32)\n",
    "        mask = nib.load(mask_path).get_fdata()[None, ..., z].astype(np.uint8)\n",
    "\n",
    "        T1w = torch.from_numpy(T1w)\n",
    "        mask = torch.from_numpy(mask)\n",
    "        \n",
    "        return T1w, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0442be3a-e0c9-425a-8251-ebb60e9b6f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Action(enum.Enum):\n",
    "    TRAIN = True\n",
    "    VALIDATE = False\n",
    "\n",
    "def run_epoch(action, loader, generator_T1map, generator_M0map, xs, ys, zs):\n",
    "\n",
    "    if action:\n",
    "        generator_T1map.train()\n",
    "    else:\n",
    "        generator_T1map.eval()\n",
    "        generator_M0map.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        volume_T1 = torch.zeros((xs,ys,zs)).to(device) #trained shape: xs=240, ys=240, zs= 224\n",
    "        volume_M0 = torch.zeros((xs,ys,zs)).to(device)\n",
    "        \n",
    "        for batch_idx, batch in enumerate(tqdm(loader)):\n",
    "            \n",
    "            \"\"\"generative network (mapping)\"\"\"\n",
    "            # T1w to T1map\n",
    "            print(batch_idx)\n",
    "\n",
    "            input_T1w = batch[0].to(device)\n",
    "            mask = batch[1].to(device)\n",
    "            input_T1w = input_T1w/4095\n",
    "\n",
    "            print(input_T1w.shape)\n",
    "\n",
    "            \"\"\"generative network (mapping)\"\"\"\n",
    "\n",
    "            # T1w to T1map\n",
    "\n",
    "            gen_t1map=generator_T1map(input_T1w) # T1w to T1map\n",
    "            gen_m0map=generator_M0map(input_T1w) # T1w to M0map\n",
    "\n",
    "            gen_t1map = mask*(gen_t1map-gen_t1map.min())*4095\n",
    "            gen_m0map = mask*(gen_m0map-gen_m0map.min())*500\n",
    "\n",
    "            volume_T1[:,:,batch_idx] = gen_t1map[0,0,:,:]          \n",
    "            volume_M0[:,:,batch_idx] = gen_m0map[0,0,:,:]\n",
    "\n",
    "        volume_T1=volume_T1.detach().cpu().numpy()\n",
    "        volume_M0=volume_M0.detach().cpu().numpy()\n",
    "        \n",
    "        return volume_T1,volume_M0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078f5d22-3fed-4f05-ba3f-4292f9ba0edb",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for sub in subjects_list: \n",
    "\n",
    "    header_data = nib.load(glob.glob(f'{data_root}/{sub}/T1w/*.nii.gz')[0])\n",
    "    sample_data = nib.load(glob.glob(f'{data_root}/{sub}/T1w/*.nii.gz')[0]).get_fdata()\n",
    "    [xs,ys,zs] = sample_data.shape\n",
    "\n",
    "    inference_dataset = CustomDataset(\n",
    "        data_root=data_root, sub_num = sub,  num_z_slice=zs, train=False,\n",
    "    )\n",
    "    \n",
    "    batch_size=1\n",
    "    inference_dl = DataLoader(inference_dataset, batch_size=batch_size, num_workers=0, shuffle=False)\n",
    "\n",
    "    generator_T1map=nets.BasicUnet(\n",
    "        in_channels=1,\n",
    "        out_channels=1,\n",
    "        spatial_dims=2,\n",
    "        features=(16,32,64,128,256,32),\n",
    "    ).to(device)\n",
    "\n",
    "    generator_M0map=nets.BasicUnet(\n",
    "        in_channels=1,\n",
    "        out_channels=1,\n",
    "        spatial_dims=2,\n",
    "        features=(16,32,64,128,256,32),\n",
    "    ).to(device)\n",
    "\n",
    "    checkpoint = torch.load(f'{state_dir}/MapG_T1.pth')\n",
    "    generator_T1map.load_state_dict(checkpoint['T1map'])\n",
    "\n",
    "    checkpoint = torch.load(f'{state_dir}/MapG_M0.pth')\n",
    "    generator_M0map.load_state_dict(checkpoint['M0map'])\n",
    "\n",
    "\n",
    "    volume_T1map,volume_M0map = run_epoch(0, inference_dl, generator_T1map, generator_M0map, xs, ys, zs)\n",
    "\n",
    "    #save results\n",
    "    \n",
    "    os.makedirs(f'{save_inference_dir}/{sub}', exist_ok=True)\n",
    "\n",
    "    save_T1_path = f'{save_inference_dir}/{sub}/pred_T1.nii.gz'\n",
    "    save_M0_path = f'{save_inference_dir}/{sub}/pred_M0.nii.gz'\n",
    "    \n",
    "    save_output = nib.Nifti1Image(volume_T1map, header_data.affine, header_data.header)\n",
    "    nib.save(save_output, f'{save_T1_path}')\n",
    "\n",
    "    save_output = nib.Nifti1Image(volume_M0map, header_data.affine, header_data.header)\n",
    "    nib.save(save_output, f'{save_M0_path}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
